{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.029718,
     "end_time": "2020-10-26T12:46:41.276296",
     "exception": false,
     "start_time": "2020-10-26T12:46:41.246578",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<img src=\"https://whatcar.vn/media/2018/09/car-lot-940x470.jpg\"/>\n",
    "\n",
    "## Прогнозирование стоимости автомобиля по характеристикам\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-10-26T12:46:41.400302Z",
     "iopub.status.busy": "2020-10-26T12:46:41.399317Z",
     "iopub.status.idle": "2020-10-26T12:46:42.581426Z",
     "shell.execute_reply": "2020-10-26T12:46:42.580431Z"
    },
    "papermill": {
     "duration": 1.219772,
     "end_time": "2020-10-26T12:46:42.581597",
     "exception": false,
     "start_time": "2020-10-26T12:46:41.361825",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from tqdm.notebook import tqdm\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_selection import f_classif, mutual_info_classif\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import auc, roc_auc_score, roc_curve\n",
    "from sklearn.ensemble import GradientBoostingRegressor, ExtraTreesRegressor, RandomForestRegressor\n",
    "\n",
    "\n",
    "from scipy.stats import boxcox\n",
    "from scipy.stats import yeojohnson, uniform\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from scipy.stats import uniform, truncnorm, randint\n",
    "from pprint import pprint\n",
    "import random\n",
    "from catboost import CatBoostRegressor\n",
    "from itertools import groupby\n",
    "\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from tqdm.notebook import tqdm\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import auc, roc_auc_score, roc_curve\n",
    "from sklearn.base import clone\n",
    "import datetime\n",
    "from datetime import datetime, timedelta\n",
    "import math\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor, AdaBoostRegressor\n",
    "from pprint import pprint\n",
    "\n",
    "from bs4 import BeautifulSoup \n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missed(lst,j,year,page,id_anchor):\n",
    "    #эта функция принимает на вход список, содержащий кортежи sell_id и признак - lst\n",
    "    #также место sell_id в кортеже - j, также год - year\n",
    "    #также - страницу - page;\n",
    "    #также список sell_id, найденных на странице - id_anchor\n",
    "    #сравниваются sell_id в списке lst и sell_id, найденные на странице\n",
    "    #если в lst не все sell_id, значит, на странице не найден\n",
    "    #признак для данного sell_id => для данного sell_id значение признака заполняется текстом 'Nan'\n",
    "\n",
    "    \n",
    "    lst1 = [x[j] for x in lst]\n",
    "    missed = list(set(id_anchor)-set(lst1))\n",
    "    for i in missed:\n",
    "        if j:\n",
    "            lst.insert(id_anchor.index(i),('Nan',i))\n",
    "        else:\n",
    "            lst.insert(id_anchor.index(i),(i,'Nan'))\n",
    "    if len(lst) > len(id_anchor):\n",
    "        print('year = {}, page = {}'.format(year,page))\n",
    "        raise Exception(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_frame_form(df_result, list_to_turn,turn_to_int, id_order, name):\n",
    "    #данная функция на вход принимает df_result - DataFrame, который будем дополнять новыми столбцами\n",
    "    #столбцы (списки) передаются в list_to_turn, каждый список содержит кортежи с sell_id и значением признака\n",
    "    #при этом в turn_to_int передается флаг - нужно ли перевести столбец из object в int (если 1, то нужно, 0 - не нужно)\n",
    "    #в id_order передается место sell_id в кортеже (0 или 1)\n",
    "    #в name передаются имена для признаков в итоговом dataframe (имена столбцов)\n",
    "    \n",
    "\n",
    "    df_new = pd.DataFrame(list_to_turn)\n",
    "    df_r = df_result.copy()\n",
    "    \n",
    "    if id_order:\n",
    "        df_new.rename(columns={0:name, 1:'sell_id'}, inplace=True)\n",
    "    else:\n",
    "        df_new.rename(columns={0:'sell_id', 1:name}, inplace=True)\n",
    "    df_new.drop_duplicates(subset=['sell_id'],inplace = True)\n",
    "    df_new['sell_id'] = df_new['sell_id'].astype(int)\n",
    "    if turn_to_int:\n",
    "        df_new[name] = df_new[name].astype(int)\n",
    "    return df_r.merge(df_new, how='left', on='sell_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def page_count(year):\n",
    "    #в данной функции мы для каждого года в списке лет - year - получаем количество страниц на auto.ru\n",
    "    #результат выводим в словарь, у которого ключи - годы, значения - количество страниц\n",
    "    \n",
    "    res = {}\n",
    "    for i in year:\n",
    "        \n",
    "        url = 'https://auto.ru/cars/'+str(i)+'-year/all/?page=1&sort=fresh_relevance_1-desc&output_type=list'\n",
    "        response = requests.get(url)\n",
    "        response.encoding = 'utf-8'\n",
    "        page = BeautifulSoup(response.text, 'html.parser')\n",
    "        res[i] = int(re.findall(r'class=\"Button__text\">([0-9]+)</span></span></a></span><div class=\"ListingPagination-module__sequenceControls', str(page))[0])\n",
    "        \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2020-10-26T12:46:42.646795Z",
     "iopub.status.busy": "2020-10-26T12:46:42.645765Z",
     "iopub.status.idle": "2020-10-26T12:46:42.649793Z",
     "shell.execute_reply": "2020-10-26T12:46:42.650407Z"
    },
    "papermill": {
     "duration": 0.040034,
     "end_time": "2020-10-26T12:46:42.650603",
     "exception": false,
     "start_time": "2020-10-26T12:46:42.610569",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Python       :', sys.version.split('\\n')[0])\n",
    "print('Numpy        :', np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2020-10-26T12:46:42.716039Z",
     "iopub.status.busy": "2020-10-26T12:46:42.715184Z",
     "iopub.status.idle": "2020-10-26T12:46:47.852433Z",
     "shell.execute_reply": "2020-10-26T12:46:47.851661Z"
    },
    "papermill": {
     "duration": 5.172536,
     "end_time": "2020-10-26T12:46:47.852593",
     "exception": false,
     "start_time": "2020-10-26T12:46:42.680057",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# зафиксируем версию пакетов, чтобы эксперименты были воспроизводимы:\n",
    "!pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-26T12:46:47.919419Z",
     "iopub.status.busy": "2020-10-26T12:46:47.918168Z",
     "iopub.status.idle": "2020-10-26T12:46:47.922267Z",
     "shell.execute_reply": "2020-10-26T12:46:47.921365Z"
    },
    "papermill": {
     "duration": 0.039842,
     "end_time": "2020-10-26T12:46:47.922434",
     "exception": false,
     "start_time": "2020-10-26T12:46:47.882592",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# всегда фиксируйте RANDOM_SEED, чтобы ваши эксперименты были воспроизводимы!\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "def mape(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_pred-y_true)/y_true))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.028837,
     "end_time": "2020-10-26T12:46:47.981435",
     "exception": false,
     "start_time": "2020-10-26T12:46:47.952598",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-26T12:46:48.05046Z",
     "iopub.status.busy": "2020-10-26T12:46:48.049412Z",
     "iopub.status.idle": "2020-10-26T12:46:48.052578Z",
     "shell.execute_reply": "2020-10-26T12:46:48.051917Z"
    },
    "papermill": {
     "duration": 0.039969,
     "end_time": "2020-10-26T12:46:48.052728",
     "exception": false,
     "start_time": "2020-10-26T12:46:48.012759",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "VERSION    = 15\n",
    "DIR_TRAIN  = '../input/den-shev/' # подключил к ноутбуку внешний датасет\n",
    "DIR_TEST   = '../input/sf-dst-car-price-prediction/'\n",
    "VAL_SIZE   = 0.20   # 20%\n",
    "\n",
    "# CATBOOST\n",
    "ITERATIONS = 5000\n",
    "LR         = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.030254,
     "end_time": "2020-10-26T12:46:48.112586",
     "exception": false,
     "start_time": "2020-10-26T12:46:48.082332",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-26T12:46:48.179769Z",
     "iopub.status.busy": "2020-10-26T12:46:48.178918Z",
     "iopub.status.idle": "2020-10-26T12:46:48.924574Z",
     "shell.execute_reply": "2020-10-26T12:46:48.925184Z"
    },
    "papermill": {
     "duration": 0.783211,
     "end_time": "2020-10-26T12:46:48.925418",
     "exception": false,
     "start_time": "2020-10-26T12:46:48.142207",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!ls '../input'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(DIR_TRAIN+'2020_12_25_0_20_out.csv') # датасет для обучения модели\n",
    "test = pd.read_csv(DIR_TEST+'test.csv')\n",
    "sample_submission = pd.read_csv(DIR_TEST+'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.car_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные для обучения необходимо добыть самостоятельно. Просмотр параметр car_url в предоставленном test (см. выше) показывает, что данные взяты с auto.ru => оттуда же буду и данные для обучения брать.\n",
    "Чтобы данных получилось побольше, буду брать данные за каждый год, начиная с 1980 по 2020.\n",
    "Данные по ссылке вида - 'https://auto.ru/cars/1980-year/all/?page=1&sort=fresh_relevance_1-desc&output_type=list'\n",
    "\n",
    "Вообще данные с auto.ru я уже выбрал в своем личном ноубуке на локальной машине, выгрузил в файл \"2020_12_25_0_20_out.csv\" и использую именно данные из файла, т.к. даже у меня на машине данные выгружаются и обрабатываются где-то 3 часа. Здесь - онлайн - будет раза в 2-2,5 дольше (ставил эксперимент).\n",
    "\n",
    "Ниже публикую код, как собирал данные с auto.ru. При желании можно его запустить, но будет часов 5-6 отрабатывать.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#в этом коде собираются данные для train\n",
    "\n",
    "\n",
    "\n",
    "description = []\n",
    "mileage = []\n",
    "model_name = []\n",
    "sell_id = []\n",
    "vendor = []\n",
    "own_num = []\n",
    "pts_r = []\n",
    "gt_r = []\n",
    "st_r = []\n",
    "custom_s = []\n",
    "pg = {}\n",
    "model_date = []\n",
    "number_of_doors = []\n",
    "vehicle_transmission = []\n",
    "price = []\n",
    "fuel_type = []\n",
    "state = []\n",
    "\n",
    "print('started at {}'.format(datetime.now()))\n",
    "\n",
    "res = page_count(range(1980,1981))\n",
    "\n",
    "for key,value in res.items():\n",
    "    for page_c in range(1,value+1):\n",
    "    \n",
    "        url = 'https://auto.ru/cars/'+str(key)+'-year/all/?page='+str(page_c)+'&sort=fresh_relevance_1-desc&output_type=list'\n",
    "        response = requests.get(url)\n",
    "        response.encoding = 'utf-8'\n",
    "        page = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        #обнаружил, что сразу много данных нужных можно удобно собрать в список pg1, см. ниже \n",
    "        \n",
    "        pg1 = re.findall(r'meta content=\\\"(.*?)\\\" itemprop=\\\"(.*?)\\\"', str(page))\n",
    "        \n",
    "        #список лучше преобразовать в словарь pg1d, где ключи - название параметров, значения - значения параметро\n",
    "        \n",
    "        pg1d = {x[1]: [y[0] for y in pg1 if y[1] == x[1] ] for x in pg1}\n",
    "        if key == 1980 and page_c == 1:\n",
    "            pg = pg1d\n",
    "        else:\n",
    "            \n",
    "            #здесь в итоговый словарь pg собираются данные с каждой страницы, т.е. в итоге в словаре для каждого ключа будет\n",
    "            #список значений параметра, собранный со всех запрошенных страниц\n",
    "            for key_1 in pg1d.keys():\n",
    "                pg[key_1] = pg[key_1] + pg1d[key_1]\n",
    "    \n",
    "        #многие параметры удобно собираются сразу в словарь pg, но достаточное количество нужно отдельно выбирать со страницы\n",
    "        #что как раз делаю ниже\n",
    "        \n",
    "        sell_id_t = re.findall(r',\\\"id\\\":\\\"([0-9]+)',str(page))\n",
    "        if len(list(set(sell_id) & set(sell_id_t))) > 0:\n",
    "            print('intersection of sell_id and sell_id_t')\n",
    "            print(list(set(sell_id) & set(sell_id_t)))\n",
    "        \n",
    "        sell_id+=sell_id_t\n",
    "\n",
    "        description_t = re.findall(r'delivery_info.*?\\\"description\\\":\\\"(.*?)\\\",\\\"discount_options.*?\\\"id\\\":\\\"([0-9]+)',str(page))\n",
    "        fill_missed(description_t,1,key,page_c,sell_id_t)\n",
    "        description+=description_t\n",
    "\n",
    "        mileage_t = re.findall(r',\\\"id\\\":\\\"([0-9]+).*?\\\"mileage\\\":(.*?),\\\"state',str(page))\n",
    "        fill_missed(mileage_t,0,key,page_c,sell_id_t)\n",
    "        mileage+=mileage_t\n",
    "\n",
    "        model_name_t = re.findall(r',\\\"id\\\":\\\"([0-9]+).*?\\\"model_info.*?name\\\":\\\"(.*?),\\\"ru_name',str(page))\n",
    "        fill_missed(model_name_t,0,key,page_c,sell_id_t)\n",
    "        model_name+=model_name_t\n",
    "\n",
    "        vendor_t= re.findall(r',\\\"id\\\":\\\"([0-9]+).*?\\\"vendor\\\":\\\"(.*?)\\\"',str(page))\n",
    "        fill_missed(vendor_t,0,key,page_c,sell_id_t)\n",
    "        vendor+=vendor_t\n",
    "\n",
    "        owners_number = re.findall(r'owners_number\\\":([0-9]+).*?\\\"id\\\":\\\"([0-9]+)',str(page))\n",
    "        own_num_t = [('3 и более',x[1]) if int(x[0]) > 2 else x for x in owners_number]\n",
    "        fill_missed(own_num_t,1,key,page_c,sell_id_t)\n",
    "        own_num+=own_num_t\n",
    "\n",
    "        pts= re.findall(r'pts\\\":\\\"(.*?)\\\".*?,\\\"id\\\":\\\"([0-9]+)\"',str(page))\n",
    "        pts_r_t = [('Оригинал',x[1]) if x[0] == 'ORIGINAL' else ('Дубликат',x[1]) for x in pts]\n",
    "        fill_missed(pts_r_t,1,key,page_c,sell_id_t)\n",
    "        pts_r+=pts_r_t\n",
    "\n",
    "        gear_type= re.findall(r',\\\"id\\\":\\\"([0-9]+).*?\\\"gear_type\\\":\\\"(.*?)\\\"',str(page))\n",
    "        gt_r_t = [(x[0],'передний') if 'forward' in x[1].lower() else (x[0],'задний') if 'rear' in x[1].lower() else (x[0],'полный') for x in gear_type]\n",
    "        fill_missed(gt_r_t,0,key,page_c,sell_id_t)\n",
    "        gt_r+=gt_r_t\n",
    "\n",
    "        st_wheel = re.findall(r',\\\"id\\\":\\\"([0-9]+).*?\\\"steering_wheel\\\":\\\"(.*?)\\\"',str(page))\n",
    "        st_r_t = [(x[0],'Левый') if 'left' in x[1].lower() else (x[0],'Правый') for x in st_wheel]\n",
    "        fill_missed(st_r_t,0,key,page_c,sell_id_t)\n",
    "        st_r+=st_r_t\n",
    "\n",
    "        custom= re.findall(r'custom_cleared\\\":(.*?)\\\".*?,\\\"id\\\":\\\"([0-9]+)\"',str(page))\n",
    "        custom_s_t = [(1,x[1]) if 'true' in x[0].lower() else (0,x[1]) for x in custom]\n",
    "        fill_missed(custom_s_t,1,key,page_c,sell_id_t)\n",
    "        custom_s+=custom_s_t\n",
    "        \n",
    "        model_date_t = re.findall(r',\\\"id\\\":\\\"([0-9]+).*?\\\"super_gen.*?,\\\"year_from\\\":([0-9]+),',str(page))\n",
    "        fill_missed(model_date_t,0,key,page_c,sell_id_t)\n",
    "        model_date+=model_date_t\n",
    "\n",
    "        nod_t = re.findall(r',\\\"id\\\":\\\"([0-9]+).*?\\\"vehicle_info.*?,\\\"doors_count\\\":([0-9]),',str(page))\n",
    "        fill_missed(nod_t,0,key,page_c,sell_id_t)\n",
    "        number_of_doors+=nod_t\n",
    "        \n",
    "        trans_t = re.findall(r',\\\"id\\\":\\\"([0-9]+).*?\\\"vehicle_info.*?,\\\"transmission\\\":\\\"(.*?)\\\",',str(page))\n",
    "        fill_missed(trans_t,0,key,page_c,sell_id_t)\n",
    "        vehicle_transmission+=trans_t\n",
    "        \n",
    "        price_t = re.findall(r',\\\"id\\\":\\\"([0-9]+).*?\\\"price\\\":([0-9]+),',str(page))\n",
    "        fill_missed(price_t,0,key,page_c,sell_id_t)\n",
    "        price+=price_t\n",
    "        \n",
    "        fuel_type_t = re.findall(r',\\\"id\\\":\\\"([0-9]+).*?\\\"engine_type\\\":\\\"(.*?)\\\",',str(page))\n",
    "        fill_missed(fuel_type_t,0,key,page_c,sell_id_t)\n",
    "        fuel_type+=fuel_type_t\n",
    "        \n",
    "        state_t = re.findall(r',\\\"id\\\":\\\"([0-9]+).*?\\\"state_not_beaten\\\":(.*?),',str(page))\n",
    "        fill_missed(state_t,0,key,page_c,sell_id_t)\n",
    "        state+=state_t\n",
    "\n",
    "        print('page {}, year {}, at {}'.format(page_c,key,datetime.now()))\n",
    "    \n",
    "print('finished at {}'.format(datetime.now()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В дальнейшем, когда я на всех собранных данных проверял, как данные собрались в общий словарь pg. Обнаружил:\n",
    "<br>1) в поле fuelType собралось вдвое больше значений, чем в остальные;\n",
    "<br>2) в поле name - втрое больше значений, чем в остальные;\n",
    "<br>3) в поле price - количество значений отличается от остальных;\n",
    "<br>4) в поле modelDate - количество значений отличается от остальных;\n",
    "<br>5) в поле numberOfDoors - количество значений отличается от остальных;\n",
    "<br>6) в поле vehicleTransmission - количество значений отличается от остальных;\n",
    "\n",
    "1,2,3 - видно даже из примера ниже.\n",
    "4,5,6 - проявляется, когда больше данных собираешь\n",
    "При этом поля image, availability - по моему мнению, никакой полезной информации не дают => я их удалил.\n",
    "Также я удалил из словаря pg 1,2,3,4,5,6, чтобы поискать их уже отдельно на странице и, если не найду, вместо них поставить 'Nan'.\n",
    "\n",
    "Поле url содержит в себе sell_id, выделю его.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in pg.keys():\n",
    "    print('key is {}, len is {}'.format(i,len(pg[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#как писал выше, удаляю из словаря все выбранные для удаления параметры\n",
    "dlist = ['fuelType','name','modelDate','numberOfDoors','vehicleTransmission','price','image','availability']\n",
    "for i in dlist:\n",
    "    pg.pop(i, None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#делаем из словаря dataframe, который будем потом дополнять данными из списков.\n",
    "df_result = pd.DataFrame(pg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#переименуем столбец \"url\" в \"sell_id\"\n",
    "df_result.rename(columns={'url':'sell_id'}, inplace=True)\n",
    "#преобразуем url в id\n",
    "df_result['sell_id'] = df_result.sell_id.str.extract(r'/([0-9]+)-').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sell_id - уникальный идентификатор строк в получившемся dataframe (в test - тоже) =>\n",
    "#удаляем из dataframe строки с повторяющимися sell_id\n",
    "\n",
    "df_result.drop_duplicates(subset=['sell_id'],inplace = True)\n",
    "df_result.sell_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#определим список параметров, в кортежах которых sell_id на 0 позиции\n",
    "list_0_0 = [model_name,vendor,gt_r,st_r,vehicle_transmission,mileage,number_of_doors,price,model_date,fuel_type,state]\n",
    "#задаем имена для столбцов, такие же, как у соответствующих столбцов у test \n",
    "list_0_0_names = ['model_name','vendor','Привод','Руль','vehicleTransmission','mileage','numberOfDoors','price','modelDate','fuelType','Состояние']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# в рамках цикла добавляем к df_result столбцы из list_0_0, используем функцию data_frame_form\n",
    "\n",
    "for i in range(0,len(list_0_0)):\n",
    "    df_result = data_frame_form(df_result,list_0_0[i],0,0,list_0_0_names[i])\n",
    "\n",
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#определим список параметров, в кортежах которых sell_id на 1 позиции\n",
    "list_0_1 = [description,pts_r,custom_s,own_num]\n",
    "\n",
    "#задаем имена для столбцов, такие же, как у соответствующих столбцов у test \n",
    "list_0_1_names = ['description','ПТС','Таможня','Владельцы']\n",
    "\n",
    "# в рамках цикла добавляем к df_result столбцы из list_0_1, используем функцию data_frame_form\n",
    "\n",
    "for i in range(0,len(list_0_1)):\n",
    "    df_result = data_frame_form(df_result,list_0_1[i],0,1,list_0_1_names[i])\n",
    "\n",
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#избавимся от пропусков в данных, делаю это, а не заполняю пропуски, потому что даже после всех чисток данных осталось > 68000 строк, \n",
    "#данных достаточно, а трудоемкость снизилась и данные настоящие, а не корректированные\n",
    "\n",
    "df_result.dropna(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# у нас также в каждом столбце есть текстовые значения \"Nan\", уберем строчки с такими значениями, \n",
    "# чтобы ни в одном столбце таких значений не осталось\n",
    "\n",
    "for i in df_result.columns:\n",
    "    df_result = df_result[df_result[i] != 'Nan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#изменю у параметров 'productionDate','mileage','numberOfDoors','price','modelDate' на Int\n",
    "\n",
    "df_result[['productionDate','mileage','numberOfDoors','price','modelDate']] = df_result[['productionDate','mileage','numberOfDoors','price','modelDate']].astype(int)\n",
    "\n",
    "df_result.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "все данные готовы, теперь их сравним попарно столбцы в test и df_result\n",
    "\n",
    "Начнем с bodyType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.bodyType.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.bodyType.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "данные готовы в df_result, ничего дополнительно делать не надо"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "смотрим brand                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.brand.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.brand.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "данные готовы в df_result, ничего дополнительно делать не надо"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "смотрим color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.color.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.color.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "данные готовы в df_result, ничего дополнительно делать не надо\n",
    "\n",
    "смотрим productionDate\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.productionDate.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.productionDate.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "данные готовы в df_result, ничего дополнительно делать не надо\n",
    "\n",
    "смотрим vehicleConfiguration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.vehicleConfiguration.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.vehicleConfiguration.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "данные готовы в df_result, ничего дополнительно делать не надо\n",
    "\n",
    "смотрим priceCurrency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.priceCurrency.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.priceCurrency.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И в df_result (и в train, который я импортировал в csv), и в test в этом признаке только 1 значение => можно признак убрать, полезной информации не добавляет. Делаю ниже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.drop(columns = ['priceCurrency'],inplace=True)\n",
    "df_result.drop(columns = ['priceCurrency'],inplace=True)\n",
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "смотрим engineDisplacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.engineDisplacement.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.engineDisplacement.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные похожи в обоих датасетах. Дополнительно можно убрать 'LTR' и сделать данные числовыми (float).\n",
    "\n",
    "Сделаем в test и сразу в train (в моем csv я этого не сделал)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.engineDisplacement = train.engineDisplacement.str.replace('LTR','',regex=True).str.replace(' ','0',regex=True).astype(float)\n",
    "test.engineDisplacement = test.engineDisplacement.str.replace('LTR','',regex=True).str.replace(' ','0',regex=True).astype(float)\n",
    "test.engineDisplacement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "смотрим enginePower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.enginePower.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.enginePower.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные похожи в обоих датасетах. Дополнительно можно убрать 'N12' и сделать данные числовыми (int).\n",
    "\n",
    "Изначально, в данных, которые я собрал с auto.ru, я еще обнаружил, что в столбце enginePower было значение 'undefined N12'. Я это значение убрал следующим образом: df_result = df_result[df_result.enginePower != 'undefined N12']\n",
    "\n",
    "Сделаем в test и сразу в train (в моем csv я этого не сделал)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.enginePower = train.enginePower.str.replace('N12','',regex=True).str.replace(' ','',regex=True).astype(int)\n",
    "test.enginePower = test.enginePower.str.replace('N12','',regex=True).str.replace(' ','',regex=True).astype(int)\n",
    "test.enginePower"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "смотрим model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.model_name.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.model_name.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "как видно, значения в столбцах похожи. Только в df_result значения заканчиваются на \". Я это значение убрал следующим образом: df_result.model_name = df_result.model_name.str[:-1]. В csv, который загрузил, это уже сделал\n",
    "\n",
    "смотрим vendor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.vendor.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.vendor.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значения похожие, т.к. значений немного имеет смысл сделать one hot encoding. Но сделаю это уже после слияния датасетов.\n",
    "\n",
    "смотрим Привод"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.Привод.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.Привод.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Аналогично vendor - значений немного имеет смысл сделать one hot encoding. Но сделаю это уже после слияния датасетов.\n",
    "\n",
    "смотрим Руль"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.Руль.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.Руль.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Когда солью датасеты. \"Левый\" = 1, \"Правый\" = 0\n",
    "\n",
    "смотрим Состояние\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.Состояние.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.Состояние.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Состояния и в df_result(в train - также), и в test - единственное значение => удаляю столбец (в загруженном train уже удален). Пользы не несет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.drop(columns = ['Состояние'],inplace=True)\n",
    "df_result.drop(columns = ['Состояние'],inplace=True)\n",
    "test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "смотрим vehicleTransmission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.vehicleTransmission.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.vehicleTransmission.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#в train ошибся и вместо \"роботизированная\" заполнил соответствующие строчки значением 'роботизировання', исправляю ниже\n",
    "train.vehicleTransmission[train.vehicleTransmission=='роботизировання'] = 'роботизированная'\n",
    "train.vehicleTransmission.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "в df_result значения в латинице, нужно перевести, чтобы было аналогично тому, как в test (в загруженном train уже сделал)ю\n",
    "Сделал так: \n",
    "\n",
    "lvt = [('механическая' if x[0] == 'M' else ('автоматическая' if x[0] == 'A' else ('вариатор' if x[0] == 'V' else 'роботизировання'))) for x in  list(df_result.vehicleTransmission.values)]\n",
    "df_result.vehicleTransmission = lvt\n",
    "\n",
    "после слияния датасетов сделаю one hot encoding.\n",
    "\n",
    "смотрим mileage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.mileage.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.mileage.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "столбцы можно совмещать. \n",
    "При выгрузке с сайта, у меня в столбце попадался \"мусор\" типа \"0,\"images_count\":14},\"sub_category\":\"cars\"...\", решил проблему следующим образом: df_result = df_result[df_result.mileage.str.match('^[0-9]+$')]\n",
    "\n",
    "в загруженном train уже сделано.\n",
    "\n",
    "Смотрим numberOfDoors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.numberOfDoors.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.numberOfDoors.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "после слияния датасетов имеет смысл удалить строчку, в которой количество дверей  = 0\n",
    "\n",
    "one hot encoding делать не буду, оставлю, как есть.\n",
    "\n",
    "смотрим modelDate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.modelDate.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.modelDate.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При выгрузке с сайта, у меня в столбце попадался \"мусор\", решил проблему следующим образом: df_result = df_result[df_result.modelDate.str.match('^[0-9]+$')]\n",
    "\n",
    "в загруженном train уже сделано.\n",
    "\n",
    "Смотрим fuelType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.fuelType.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.fuelType.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "в df_result значения в латинице, нужно перевести, чтобы было аналогично тому, как в test (в загруженном train уже сделал). Сделал так:\n",
    "\n",
    "<br>ft = [('бензин' if x[0] == 'G' else ('дизель' if x[0] == 'D' else ('гибрид' if x[0] == 'H' else ('электро' if x[0] == 'E' else 'газ')))) for x in list(df_result.fuelType.values)]\n",
    "\n",
    "<br>df_result.fuelType = ft\n",
    "\n",
    "после слияния датасетов сделаю one hot encoding.\n",
    "\n",
    "смотрим description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "очень много текста, совсем неочевидно, как из этого извлечь пользу => удаляю столбцы в test и df_result. В train уже сделано."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.drop(columns = ['description'],inplace=True)\n",
    "df_result.drop(columns = ['description'],inplace=True)\n",
    "test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Смотрим ПТС"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.ПТС.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.ПТС.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Когда солью датасеты. \"Оригинал\" = 1, \"Дубликат\" = 0\n",
    "\n",
    "смотрим Таможня"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.Таможня.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.Таможня.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таможня и в df_result(в train - также), и в test - единственное значение => удаляю столбец (в загруженном train уже удален). Пользы не несет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.drop(columns = ['Таможня'],inplace=True)\n",
    "df_result.drop(columns = ['Таможня'],inplace=True)\n",
    "test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Смотрим Владельцы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.Владельцы.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.Владельцы.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "нужно, чтобы у train были такие же значения, как и у test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(train.Владельцы.value_counts().index)):\n",
    "   \n",
    "    train.Владельцы[train.Владельцы == train.Владельцы.value_counts().index[i]] = test.Владельцы.value_counts().index[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.Владельцы.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "после слияния сделаю one hot encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "все совпадающие поля у train и test проверили и обработали.\n",
    "Выясним, какие у test остались столбцы, которых нет у train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(set(list(test.columns)) - set(list(train.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "первое, что необходимо сделать - переименовать столбец \"id\" в \"sell_id\" у train. Делаю"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.rename(columns={'id':'sell_id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(set(list(test.columns)) - set(list(train.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "рассмотрим столбец equipment_dict у test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.equipment_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "содержит словари, в которых много данных, причем, ключи неоднородные в словарях => будет сложно пользу извлечь из такого параметра => удаляю"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.drop(columns = ['equipment_dict'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "столбец image надо удалять, не глядя). Удаляю."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.drop(columns = ['image'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "рассмотрим столбец super_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.super_gen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "словарь со множеством ключей, которые не одинаковые в разных строках => пользу будет очень тяжело извлечь. Удаляю"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.drop(columns = ['super_gen'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "рассмотрим столбец model_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.model_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "словарь, который содержит данные из столбцов model_name, brand => словарь + избыточная информация => удаляю."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.drop(columns = ['model_info'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "рассмотрим столбец name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "в столбце собраны данные из других столбцов engineDisplacement, enginePower => избыточность, удаляю."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.drop(columns = ['name'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "рассмотрим столбец Владение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.Владение.value_counts(normalize=True,dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "в столбце 65% значений пропущено => удаляю столбец"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.drop(columns=['Владение'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "столбец car_url - считаю, что от ссылки пользы нет, она содержит sell_id, который у нас выделен в отдельный столбец => удаляю."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.drop(columns=['car_url'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "рассмотрим столбец complectation_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.complectation_dict.value_counts(normalize=True,dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "содержит страшные словари) + 81% - пропуски, удаляю столбец вообще без сожалений)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.drop(columns = ['complectation_dict'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "столбец parsing_unixtime - юниксовое время, когда test распарсили - не понимаю, какая польза от этого может быть => удаляю"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.drop(columns = ['parsing_unixtime'],inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(set(list(test.columns)) - set(list(train.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "мы готовы к слиянию датасетов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train['Train'] = 1 # помечаем где у нас трейн\n",
    "test['Train'] = 0 # помечаем где у нас тест\n",
    "\n",
    "df = pd.concat([df, test], axis=0).reset_index(drop=True)\n",
    "df.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Train'] = 1 # помечаем где у нас трейн \n",
    "test['Train'] = 0 # помечаем где у нас тест\n",
    "\n",
    "df = pd.concat([train, test], axis=0).reset_index(drop=True) \n",
    "df.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "проверим, что в итоговом датасете получилось"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "как видим, в итоговом датасете отсуствуют price - это понятно, т.к. в test не было столбца с price. Также отсутствует 1 значение в столбце \"ПТС\" => заполню самым распространенным значением"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.ПТС[df.ПТС.isnull()] = 'Оригинал'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Разделим данные на группы переменных:¶\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По итогам рассмотрения столбцов, решил:\n",
    "\n",
    "<br>1) vendor, Привод, vehicleTransmission, fuelType, Владельцы - применю One hot encoding\n",
    "\n",
    "<br>2) Руль, ПТС - binary кодирование:\n",
    "\n",
    "Руль -  \"Левый\" = 1, \"Правый\" = 0\n",
    "ПТС - \"Оригинал\" = 1, \"Дубликат\" = 0\n",
    "\n",
    "<br>3) productionDate, engineDisplacement, enginePower, mileage,numberOfDoors, modelDate - числовые столбцы;\n",
    "\n",
    "<br> 4) bodyType, brand, color, vehicleConfiguration, model_name - категориальные переменные, которые закодирую через data[colum].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_cols = ['vendor', 'Привод', 'vehicleTransmission', 'fuelType', 'Владельцы']\n",
    "cat_cols = ['bodyType', 'brand', 'color', 'model_name','vehicleConfiguration'] # категориальные переменные\n",
    "num_cols = ['modelDate', 'productionDate', 'mileage', 'numberOfDoors',\n",
    "            'enginePower','engineDisplacement'] # числовые переменные"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Числовые признаки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in num_cols:\n",
    "    plt.figure()\n",
    "    sns.distplot(df[i])\n",
    "    plt.title(i)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Посмотрим корреляцию числовых признаков\n",
    "correlation = df[num_cols].corr()\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(correlation, annot=True, cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.enginePower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.engineDisplacement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из графика видно:\n",
    "<br>+0.95 между modelDate и productionDate. Для анализа оставим productionDate\n",
    "<br>+0.81 между enginePower и engineDisplacement. Оставлю engineDisplacement (меньше разлет значений)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.drop(columns = ['modelDate','enginePower'])\n",
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#делаем One hot кодирование для выбранных столбцов\n",
    "for i in one_hot_cols:\n",
    "    dummies = pd.get_dummies(df1[i],prefix=i)\n",
    "    for j in dummies.columns:\n",
    "        df1[j] = dummies[j]\n",
    "    df1.drop(columns = i,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "кодируем категориальные признаки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for colum in cat_cols:\n",
    "    df1[colum] = df1[colum].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "кодируем бинарные Руль и ПТС\n",
    "\n",
    "Руль - \"Левый\" = 1, \"Правый\" = 0 ПТС - \"Оригинал\" = 1, \"Дубликат\" = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.Руль[df1.Руль == 'Левый'] = 1\n",
    "df1.Руль[df1.Руль == 'Правый'] = 0\n",
    "df1.Руль = df1.Руль.astype(int)\n",
    "df1.ПТС[df1.ПТС == 'Оригинал'] = 1\n",
    "df1.ПТС[df1.ПТС == 'Дубликат'] = 0\n",
    "df1.ПТС = df1.ПТС.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.Руль.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.ПТС.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#сохраняем значения целевого параметра\n",
    "y = df1['price'][df1['Train'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-26T12:47:03.6352Z",
     "iopub.status.busy": "2020-10-26T12:47:03.633973Z",
     "iopub.status.idle": "2020-10-26T12:47:03.646722Z",
     "shell.execute_reply": "2020-10-26T12:47:03.645899Z"
    },
    "papermill": {
     "duration": 0.06183,
     "end_time": "2020-10-26T12:47:03.646867",
     "exception": false,
     "start_time": "2020-10-26T12:47:03.585037",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-26T12:47:03.727044Z",
     "iopub.status.busy": "2020-10-26T12:47:03.725742Z",
     "iopub.status.idle": "2020-10-26T12:47:03.753844Z",
     "shell.execute_reply": "2020-10-26T12:47:03.753001Z"
    },
    "papermill": {
     "duration": 0.071275,
     "end_time": "2020-10-26T12:47:03.754",
     "exception": false,
     "start_time": "2020-10-26T12:47:03.682725",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = df1[df1.Train == 1].drop(columns = ['Train','sell_id','price'])\n",
    "X_sub = df1[df1.Train == 0].drop(columns = ['Train','sell_id','price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.035737,
     "end_time": "2020-10-26T12:47:03.826552",
     "exception": false,
     "start_time": "2020-10-26T12:47:03.790815",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Train Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VAL_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-26T12:47:03.90948Z",
     "iopub.status.busy": "2020-10-26T12:47:03.908518Z",
     "iopub.status.idle": "2020-10-26T12:47:03.923409Z",
     "shell.execute_reply": "2020-10-26T12:47:03.922602Z"
    },
    "papermill": {
     "duration": 0.059208,
     "end_time": "2020-10-26T12:47:03.923564",
     "exception": false,
     "start_time": "2020-10-26T12:47:03.864356",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=VAL_SIZE, shuffle=True, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1: Создадим \"наивную\" модель \n",
    "Эта модель будет предсказывать среднюю цену по модели двигателя (engineDisplacement). \n",
    "C ней будем сравнивать другие модели.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_train = X_train.copy()\n",
    "tmp_train['price'] = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Находим median по экземплярам engineDisplacement в трейне и размечаем тест\n",
    "predict = X_test['engineDisplacement'].map(tmp_train.groupby('engineDisplacement')['price'].median())\n",
    "\n",
    "#оцениваем точность\n",
    "print(f\"Точность наивной модели по метрике MAPE: {(mape(y_test, predict.values))*100:0.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.037164,
     "end_time": "2020-10-26T12:47:03.997616",
     "exception": false,
     "start_time": "2020-10-26T12:47:03.960452",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# # Model 2 : CatBoost\n",
    "![](https://pbs.twimg.com/media/DP-jUCyXcAArRTo.png:large)   \n",
    "\n",
    "\n",
    "У нас в данных практически все признаки категориальные. Специально для работы с такими данными была создана очень удобная библиотека CatBoost от Яндекса. [https://catboost.ai](http://)     \n",
    "На данный момент **CatBoost является одной из лучших библиотек для табличных данных!**\n",
    "\n",
    "#### Полезные видео о CatBoost (на русском):\n",
    "* [Доклад про CatBoost](https://youtu.be/9ZrfErvm97M)\n",
    "* [Свежий Туториал от команды CatBoost (практическая часть)](https://youtu.be/wQt4kgAOgV0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.035833,
     "end_time": "2020-10-26T12:47:04.149539",
     "exception": false,
     "start_time": "2020-10-26T12:47:04.113706",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-26T12:47:04.256865Z",
     "iopub.status.busy": "2020-10-26T12:47:04.248328Z",
     "iopub.status.idle": "2020-10-26T12:48:12.17834Z",
     "shell.execute_reply": "2020-10-26T12:48:12.17762Z"
    },
    "papermill": {
     "duration": 67.991521,
     "end_time": "2020-10-26T12:48:12.178488",
     "exception": false,
     "start_time": "2020-10-26T12:47:04.186967",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = CatBoostRegressor(iterations = ITERATIONS,\n",
    "                          learning_rate = LR,\n",
    "                          random_seed = RANDOM_SEED,\n",
    "                          eval_metric='MAPE',\n",
    "                          custom_metric=['R2', 'MAE']\n",
    "                         )\n",
    "model.fit(X_train, y_train,\n",
    "         #cat_features=cat_features_ids,\n",
    "         eval_set=(X_test, y_test),\n",
    "         verbose_eval=100,\n",
    "         use_best_model=True,\n",
    "         plot=True\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-26T12:48:12.389716Z",
     "iopub.status.busy": "2020-10-26T12:48:12.388722Z",
     "iopub.status.idle": "2020-10-26T12:48:12.393213Z",
     "shell.execute_reply": "2020-10-26T12:48:12.392387Z"
    },
    "papermill": {
     "duration": 0.135345,
     "end_time": "2020-10-26T12:48:12.393406",
     "exception": false,
     "start_time": "2020-10-26T12:48:12.258061",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save_model('catboost_single_model_baseline.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.predict(X_test)\n",
    "\n",
    "# оцениваем точность\n",
    "print(f\"Точность модели по метрике MAPE: {(mape(y_test, predict))*100:0.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.088891,
     "end_time": "2020-10-26T12:48:12.562943",
     "exception": false,
     "start_time": "2020-10-26T12:48:12.474052",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Вот так просто со старта, даже не трогая сами данные и не подбирая настройки catboosta, получаем модель с уровнем ошибки в 30.05%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(random_state=42)\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "test_predict = rf.predict(X_test)\n",
    "print(f\"Test MAPE: {mape(y_test, test_predict)*100:0.3f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeRegressor(max_features=int(X_train.shape[1]/3), max_depth=50)\n",
    "tree.fit(X_train, y_train)\n",
    "test_predict = tree.predict(X_test)\n",
    "print(f\"DecisionTreeRegressor Test MAPE: {mape(y_test, test_predict)*100:0.3f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X1, y, test_size=VAL_SIZE, shuffle=True, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GradientBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = GradientBoostingRegressor(max_depth=7,n_estimators=1000,learning_rate=0.1,random_state=42)\n",
    "gb.fit(X_train, y_train)\n",
    "test_predict = gb.predict(X_test)\n",
    "print(f\"GradientBoostingRegressor Test MAPE: {mape(y_test, test_predict)*100:0.3f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.085876,
     "end_time": "2020-10-26T12:48:12.734207",
     "exception": false,
     "start_time": "2020-10-26T12:48:12.648331",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-26T12:48:12.920825Z",
     "iopub.status.busy": "2020-10-26T12:48:12.919528Z",
     "iopub.status.idle": "2020-10-26T12:48:13.047456Z",
     "shell.execute_reply": "2020-10-26T12:48:13.046446Z"
    },
    "papermill": {
     "duration": 0.221439,
     "end_time": "2020-10-26T12:48:13.047693",
     "exception": false,
     "start_time": "2020-10-26T12:48:12.826254",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predict_submission = gb.predict(X_sub)\n",
    "predict_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "лучше всего себя показала GradientBoosting, буду сдаваться с этой моделью."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-26T12:48:13.227584Z",
     "iopub.status.busy": "2020-10-26T12:48:13.226285Z",
     "iopub.status.idle": "2020-10-26T12:48:13.762529Z",
     "shell.execute_reply": "2020-10-26T12:48:13.763259Z"
    },
    "papermill": {
     "duration": 0.628302,
     "end_time": "2020-10-26T12:48:13.763488",
     "exception": false,
     "start_time": "2020-10-26T12:48:13.135186",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_submission['price'] = predict_submission\n",
    "sample_submission.to_csv(f'submission_v{VERSION}.csv', index=False)\n",
    "sample_submission.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.080788,
     "end_time": "2020-10-26T12:48:14.596978",
     "exception": false,
     "start_time": "2020-10-26T12:48:14.51619",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
